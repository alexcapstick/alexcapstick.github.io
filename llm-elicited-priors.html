<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="In this work we present a method for using large language models to elicit expert priors for linear predictive models and demonstrate how human experts can aid the process. We then compare these posterior predictions with those made through in-context learning, where language models make predictions directly.">
  <meta property="og:title"
    content="AutoElicit: Using Large Language Models for Expert Prior Elicitation in Predictive Modelling" />
  <meta property="og:description"
    content="In this work we present a method for using large language models to elicit expert priors for linear predictive models and demonstrate how human experts can aid the process. We then compare these posterior predictions with those made through in-context learning, where language models make predictions directly." />
  <meta property="og:url" content="https://alexcapstick.github.io/llm-elicited-priors" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="llm-elicited-priors/static/images/banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="526" />


  <meta name="twitter:title"
    content="AutoElicit: Using Large Language Models for Expert Prior Elicitation in Predictive Modelling">
  <meta name="twitter:description"
    content="In this work we present a method for using large language models to elicit expert priors for linear predictive models and demonstrate how human experts can aid the process. We then compare these posterior predictions with those made through in-context learning, where language models make predictions directly.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="llm-elicited-priors/static/images/banner_image.png">
  <meta name="twitter:card" content="The process for eliciting expert priors from LLMs">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="LLMS, Large language models, prior elicitation, expert priors">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LLM-Elicited Priors</title>
  <link rel="icon" type="image/x-icon" href="llm-elicited-priors/static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="llm-elicited-priors/static/css/bulma.min.css">
  <link rel="stylesheet" href="llm-elicited-priors/static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="llm-elicited-priors/static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="llm-elicited-priors/static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="llm-elicited-priors/static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="llm-elicited-priors/static/js/fontawesome.all.min.js"></script>
  <script src="llm-elicited-priors/static/js/bulma-carousel.min.js"></script>
  <script src="llm-elicited-priors/static/js/bulma-slider.min.js"></script>
  <script src="llm-elicited-priors/static/js/index.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title publication-title">AutoElicit: Using
              Large Language Models for Expert Prior Elicitation in
              Predictive Modelling</h1>
              <div class="journal-name">
                <p>Accepted at the International Conference on Machine Learning (ICML) 2025</p>
              </div>
            <div class="publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <div class="author-name">
                  <a class="author-name-text" href="https://alexcapstick.github.io/" target="_blank">Alexander
                    Capstick</a>
                  <p class="author-affiliation">Imperial College London</p>
                  <p class="author-affiliation">CR & T, UKDRI</p>

                </div>
                <div class="author-name">
                  <a class="author-name-text" href="https://www.cs.toronto.edu/~rahulgk/" target="_blank">Rahul G
                    Krishnan</a>
                  <p class="author-affiliation">University of Toronto</p>
                  <p class="author-affiliation">Vector Institute</p>
                </div>
                <div class="author-name">
                  <a class="author-name-text" href="https://profiles.imperial.ac.uk/p.barnaghi" target="_blank">Payam
                    Barnaghi</a>
                  <p class="author-affiliation">Imperial College London</p>
                  <p class="author-affiliation">CR & T, UKDRI</p>
                  <p class="author-affiliation">DRIVE unit, GOSH</p>
                </div>
                <!-- <a href="https://alexcapstick.github.io/" target="_blank">Alexander Capstick</a>,
              </span>
              <span class="author-block">
                <a href="https://www.cs.toronto.edu/~rahulgk/" target="_blank">Rahul G Krishnan</a>,</span>
              <span class="author-block">
                <a href="https://profiles.imperial.ac.uk/p.barnaghi" target="_blank">Payam Barnaghi</a> -->
              </span>
            </div>

            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block">Institution Name<br>Conferance name and year</span>
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2411.17284" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span class="publication-link-text">Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <!-- <span class="link-block">
                  <a href="llm-elicited-priors/static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span class="publication-link-text">Supplementary</span>
                  </a>
                </span> -->

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/alexcapstick/llm-elicited-priors" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span class="publication-link-text">Reproduce paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/alexcapstick/autoelicit" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span class="publication-link-text">Implement method</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2411.17284" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span class="publication-link-text">arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section hero ">
    <div class="container is-max-desktop">
      <div>
        <a href="https://github.com/alexcapstick/autoelicit" target="_blank">
          <img class="figure" src="./llm-elicited-priors/static/images/autoelicit_logo.png" style="width: 50%; margin-top: 0em" />
        </a>
        <h2 class="figure-caption has-text-centered">
          To implement these methods, please use the python package: <br><a
            href="https://github.com/alexcapstick/autoelicit" target="_blank"><code
              style="text-decoration: underline">pip install autoelicit</code></a>
        </h2>
      </div>
    </div>
  </section>




  <!-- Paper introduction -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">Summary</h2>
          <div class="content section-text section-box">
            <p>
              In this work we present a method for using large language models to elicit expert priors for linear
              predictive models and demonstrate how human experts can aid the process. We then compare these posterior
              predictions with those made through in-context learning, where language models make predictions directly.
              For this comparison, we estimate the in-context prior and posterior distributions and use the Bayes factor
              for model selection.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section hero ">
    <div class="container is-max-desktop">
      <div><img class="figure" src="./llm-elicited-priors/static/images/figure_1_more_info.png" />
        <h2 class="figure-caption has-text-centered">
          How we propose to perform prior elicitation for predictive tasks using a language model.
        </h2>
      </div>
    </div>
  </section>



  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
  <!-- Your video here -->
  <!-- <source src="llm-elicited-priors/static/videos/banner_video.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat
          pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">Abstract</h2>
          <div class="content section-text section-box">
            <p>
              Large language models (LLMs) acquire a breadth of information across various domains. However, their
              computational complexity, cost, and lack of transparency often hinder their direct application for
              predictive tasks where privacy and interpretability are paramount. In fields such as healthcare, biology,
              and finance, specialised and interpretable linear models still hold considerable value. In such domains,
              labelled data may be scarce or expensive to obtain. Well-specified prior distributions over model
              parameters can reduce the sample complexity of learning through Bayesian inference; however, eliciting
              expert priors can be time-consuming. We therefore introduce AutoElicit to extract knowledge from LLMs and
              construct priors for predictive models. We show these priors are informative and can be refined using
              natural language. We perform a careful study contrasting AutoElicit with in-context learning and
              demonstrate how to perform model selection between the two methods. We find that AutoElicit yields priors
              that can substantially reduce error over uninformative priors, using fewer labels, and consistently
              outperform in-context learning. We show that AutoElicit saves over 6 months of labelling effort when
              building a new predictive model for urinary tract infections from sensor recordings of people living with
              dementia.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->



  <!-- Task descriptions -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">The task descriptions</h2>
          <div class="content section-text section-box">
            <p>
              For a given task, we write a single user role and system role. We can then ask a language model to
              rephrase these roles \( k \) times each. By taking the product of these roles to form each prompt, we
              create \( k^2 \) unique task descriptions that define the problem setting. These task descriptions should
              all convey the same instruction and so allow us to capture some of the language model's variation to the
              way we specify the task.
            </p>
            <p>
              As a synthetic example, we ask the language model to provide a prior distribution
              over the parameters of a linear model trying to make predictions on the following generated dataset:
              \[ y = 2x_1 - x_2 + x_3 \] where \( x_1, x_2, x_3 \) are the features and \( y \) is the target and \( X
              \sim N(0,1) \).
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section hero ">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths  section-text">
          <p class="prompt-example system-role-example">
            <strong>System role:</strong> You're a linear regression predictor, estimating the target based on
            some input features. The known relationship is:
            'target' = 2 * 'feature 0' - 1 * 'feature 1' + 1 * 'feature 2'.
            Use this to predict the target value.
          </p>
          <p class="prompt-example user-role-example">
            <strong>User role:</strong> I am a data scientist working with a dataset for a prediction task using
            feature values to predict a target. I would like to apply your model to
            predict the target for my samples. My dataset consists of these
            features: ['feature 0', 'feature 1', 'feature 2']. All the values have been standardized using z-scores. The
            known relationship is:
            'target' = 2 * 'feature 0' - 1 * 'feature 1' + 1 * 'feature 2'.
            Based on the correlation between each feature and target,
            whether positive or negative, please guess the mean and standard
            deviation for a normal distribution prior for each feature. I need
            this for creating a linear regression model to predict the target.
            Provide your response as a JSON object with the feature names as keys,
            each containing a nested dictionary for the mean and standard deviation.
            A positive mean suggests positive correlation with the outcome, negative
            for negative correlation, and a smaller standard deviation indicates
            higher confidence. Only respond with JSON.
          </p>
        </div>
      </div>
    </div>
  </section>


  <!-- Prior elicitation -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">Eliciting priors from language models</h2>
          <div class="content section-text section-box">
            <p>
              We use these rephrased task descriptions to elicit many Gaussian priors. We obtain a single Gaussian
              distribution for each feature, for each task description. By using a mixture of these distributions, we
              can construct the general prior knowledge of the language model on the features of a linear model.
            </p>
            <p>
              Formally, given a language model \( M \) and task \( T \), we will obtain a single Gaussian prior for each
              feature, for each task description \( I \).
            </p>
            <p>
              This is done by prompting the language model to provide a guess of the mean and standard deviation of a
              Gaussian prior for each feature on a linear model for a task description. From this we obtain a mean \(
              \mu_k \) and standard deviation \( \sigma_k \) for each feature, for a given task description \( I_k \).
            </p>
            <p>
              By taking a mixture of these individual Gaussian distributions, we construct a prior \( \Pr_{M,T}(\theta)
              \) over our model parameters \( \theta \). With mixing weights for each task description \( \pi_k \sim Dir
              (1) \), this prior is given by:
              \[ \Pr_{M, T}(\theta) = \sum_{k=1}^K \pi_k N ( \theta | \mu_k, {\sigma_k}^2 ) \]
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Prior elicitation -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content section-text section-box">
            <p>
              As an example, after combining the elicited distributions from synthetic task above, \( y = 2x_1 - x_2 +
              x_3 \), we arrive at the following prior distribution on a linear regressor:
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero ">
    <div class="container is-max-desktop">
      <div><img class="figure" style="width: 75%"
          src="./llm-elicited-priors/static/images/fake_data_prior_samples_pe.png" />
        <h2 class="figure-caption has-text-centered">
          Histogram of the prior parameter samples elicited from GPT-3.5-turbo for the synthetic regression task.
        </h2>
      </div>
    </div>
  </section>


  <!-- Prior elicitation -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content section-text section-box">
            <p>
              The elicited prior distribution is what we might expect, since we provided the LLM with the equation to
              produce the data. Along with this example, we also evaluate the language model's prior elicitation
              capabilities on a number of real-world tasks. We use Monte Carlo methods to sample the accuracy of
              the posterior predictive distribution on a test set after we have provided varied numbers of training
              examples (to the sampler, not the LLM). The uninformative prior in the below is a standard normal
              distribution.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section hero ">
    <div class="container is-max-desktop">
      <div><img class="figure" src="./llm-elicited-priors/static/images/elicitation_results_lineplot.png" />
        <h2 class="figure-caption has-text-centered">
          Line plot of the accuracy and MSE of the posterior predictive distribution on a test set, using the
          LLM-elicited priors and the uninformative prior.
        </h2>
      </div>
    </div>
  </section>



  <!-- Prior elicitation -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content section-text section-box">
            <p>
              In almost all cases, one of the LLM-elicited priors outperforms the uninformative prior, particularly when
              data is sparse.
              This is particularly interesting for the UTI prediction task, where the data is private and will have
              never appeared in the LLM's training text.
            </p>
            <p>
              For the Hypothyroid prediction task, the GPT-3.5-turbo-elicited prior performs similarly for the low-data
              regime but allows
              the model to learn more from the data as the number of examples increases.
              In this case, DeepSeek-R1-32B-Q4 produces considerably more accurate posteriors.
            </p>
            <p>
              In the case of Heart Disease
              prediction, GPT-3.5-turbo returned an uninformative prior for most of the task descriptions, indicating
              its lack of knowledge of the domain.
              This suggests the use of human experts in communication with the
              LLM
              to help steer the language model towards producing more informative prior distributions when it
              has little prior knowledge.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Do experts help -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">How to use human expert knowledge to guide the language model</h2>
          <div class="content section-text section-box">
            <p>
              By additionally providing the language model with expert knowledge, we can guide the LLM to return more
              informative priors. This can be helpful when practitioners have access to a domain expert, but it is
              challenging for them to define the parameters of a prior distribution.
            </p>
            <p>
              In the following figure, we use the synthetic task as an example. Here, we provide increasingly more
              informative information about the task to the language model and observe the expected changes in the
              elicited prior distribution. For each level of information, we describe to the language model how an
              additional feature relates to the target using natural language.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section hero ">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths  section-text">
          <p class="prompt-example mutable-role-example-1">
            <strong>One feature relationship provided:</strong> The known
            relationship is: the target is a linear combination of the features
            and when 'feature 0' increases by 1, the target increases by 2.
          </p>
          <p class="prompt-example mutable-role-example-2">
            <strong>Two feature relationships provided:</strong> The known
            relationship is: the target is a linear combination of the features
            and when 'feature 0' increases by 1, the target increases by 2, and
            when 'feature 1' increases by 1, the target decreases by 1.
          </p>
          <p class="prompt-example mutable-role-example-3">
            <strong>Three feature relationships provided:</strong> The known
            relationship is: the target is a linear combination of the features
            and when 'feature 0' increases by 1, the target increases by 2, and
            when 'feature 1' increases by 1, the target decreases by 1, and when
            'feature 2' increases by 1, the target increases by 1.
          </p>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero ">
    <div class="container is-max-desktop">
      <div><img class="figure" style="width: 75%;"
          src="./llm-elicited-priors/static/images/elicitation_varied_descriptions_prior_parameter_distribution.png" />
        <h2 class="figure-caption has-text-centered">
          The change in the GPT-3.5-turbo prior parameter distribution as the language model is provided with more
          information about
          the task.
        </h2>
      </div>
    </div>
  </section>


  <!-- Do experts help -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content section-text section-box">
            <p>
              The same can be done on the UTI task, where we are able to provide additional information about the
              positive
              correlation between UTI risk and the bathroom frequency, night-time disturbances, and the number of
              previous UTIs.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section hero ">
    <div class="container is-max-desktop">
      <div><img class="figure" src="./llm-elicited-priors/static/images/uti_with_expert_information.png" />
        <h2 class="figure-caption has-text-centered">
          The change in the LLM-elicited prior parameter distribution when we provide
          expert information for the UTI task, and the effect on the posterior accuracy.
        </h2>
      </div>
    </div>
  </section>


  <!-- Do experts help -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content section-text section-box">
            <p>
              This figure shows how the language model updated its previously elicited prior distribution for
              the UTI task. As we can see, the LLM-elicited distributions already captured the correct correlation
              direction, but our additional information resulted in prior distributions with a greater value.
              Since the difference in prior distributions is small, this leads to only a small increase in the
              posterior accuracy. It does however demonstrate the combined use of experts and LLMs for prior
              elicitation, since the language model reliably converts the expert's natural language into prior
              distributions.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Other language models -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">Other language models for prior elicitation</h2>
          <div class="content section-text section-box">
            <p>
              We can also evaluate the prior elicitation capabilities of other language models. Here, we compare
              open-source LLMs and some of the other available OpenAI models to those presented above:
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section hero ">
    <div class="container is-max-desktop">
      <div class=""><img class="figure"
          src="./llm-elicited-priors/static/images/elicitation_results_lineplot_gpts.png" />
        <h2 class="figure-caption has-text-centered">
          Line plot of the accuracy and MSE of the posterior predictive distribution on a test set, using the
          LLM-elicited prior from other OpenAI models.
        </h2>
      </div>
    </div>
  </section>


  <section class="section hero ">
    <div class="container is-max-desktop">
      <div class=""><img class="figure"
          src="./llm-elicited-priors/static/images/elicitation_results_lineplot_other_llms.png" />
        <h2 class="figure-caption has-text-centered">
          Line plot of the accuracy and MSE of the posterior predictive distribution on a test set, using the
          LLM-elicited prior from common open-source models.
        </h2>
      </div>
    </div>
  </section>

  <!-- Other language models -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content section-text section-box">
            <p>
              We mostly find that the open-source models provide priors with inconsistent posterior performance. The
              exception is
              DeepSeek-R1-32B-Q4, which suggests that recent developments in reasoning methods are helpful for
              eliciting priors.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- Comparison to in-context learning -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">Parallels to in-context learning</h2>
          <div class="content section-text section-box">
            <p>
              Since we are using a language model's prior knowledge and updating it with a training dataset to make
              predictions, this method is a direct alternative to in-context learning for numerical predictive tasks.
              The difference being that prior elicitation uses a marginal distribution and Bayesian inference to address
              some of the shortfalls of in-context learning.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- Extracting in-context priors -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="section-title">We can approximate the in-context prior and posterior distributions</h2>
          <div class="content section-text section-box">
            <p>
              We present an approach for extracting the in-context prior distribution when the predictions mimic a
              linear model by sampling a maximum likelihood estimation (MLE) estimator. We construct a synthetic
              dataset, and given a task description, ask the language model to make predictions. We specify that the
              in-context predictions must be made using a linear model. If the language model has used a linear model to
              make its regression or classification probability predictions, we can use MLE to sample from the
              in-context model's prior and posterior distributions. From this we can construct sampling
              distributions of the parameters of the hidden in-context model.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section hero ">
    <div class="container is-max-desktop">
      <div class=""><img class="figure" src="./llm-elicited-priors/static/images/prior_extraction_grid.png" />
        <h2 class="figure-caption has-text-centered">
          Histograms of the <em>prior</em> parameter samples approximated through MLE sampling of
          in-context predictions, and the error in our approximation.
        </h2>
      </div>
    </div>
  </section>



  <!-- Extracting in-context priors -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content section-text section-box">
            <p>
              The approximated prior distributions for the in-context learning model are shown above. The upper row
              shows the histograms of parameters for each of the tasks, whilst the lower row shows the error in our
              approximations. We measure this by comparing the error in the predictions made using in-context learning
              and those made by the MLE approximations of the in-context model.
            </p>
          </div>
        </div>
      </div>
    </div>




    <section class="section hero ">
      <div class="container is-max-desktop">
        <div class=""><img class="figure" style="width: 83.3%"
            src="./llm-elicited-priors/static/images/posterior_extraction_grid.png" />
          <h2 class="figure-caption has-text-centered">
            Histograms of the <em>posterior</em> parameter samples approximated through MLE sampling of
            in-context predictions, and the error in our approximation.
          </h2>
        </div>
      </div>
    </section>



    <!-- Extracting in-context priors -->
    <section class="section hero">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content section-text section-box">
              <p>
                The above shows the posterior distributions approximated from the in-context predictions in the same
                way,
                except that the prompt also contains demonstration examples from the training data, which the in-context
                model
                should be using to update its prior knowledge.
              </p>
              <p>
                We can see that our approximation of the internal posterior model is not as
                accurate as the internal prior model. This is because
                the LLM is inconsistently imitating a linear model as we instructed, likely because the prompt
                significantly increases in size once we include data points as examples.
              </p>
            </div>
          </div>
        </div>
      </div>



      <!-- Do our priors look like those in-context? -->
      <section class="section hero">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="section-title">The in-context priors differ from the ones we elicit</h2>
              <div class="content section-text section-box">
                <p>
                  In the figure below we can then compare visually, and using the energy statistic, the difference
                  between
                  the approximated in-context prior distributions and the ones elicited from the language model.
                  Discounting the synthetic task which shows a high error in our approximation, we see that the
                  distributions elicited from the LLM differ significantly from those used by the language model
                  in-context. Either the language model is not reliably returning its own priors when we perform prior
                  elicitation, or it is not using that prior knowledge when making predictions in-context. We suspect
                  the
                  latter, since the elicited priors match our expectation on the UTI and synthetic tasks, and the
                  in-context priors often centre around 0.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>


      <section class="section hero ">
        <div class="container is-max-desktop">
          <div><img class="figure"
              src="./llm-elicited-priors/static/images/prior_extraction_icl_pe_grid_low_approx_error.png" />
            <h2 class="figure-caption has-text-centered">
              Histograms of the prior parameter samples approximated through MLE sampling of
              in-context predictions compared to those elicited from GPT-3.5-turbo.
            </h2>
          </div>
        </div>
      </section>


      <!-- Does in-context learning approximate bayesian inference? -->
      <section class="section hero">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="section-title">In-context learning is not consistently approximating Bayesian inference
              </h2>
              <div class="content section-text section-box">
                <p>
                  Since we can also approximate the in-context model's posterior distribution by providing training
                  examples in the prompt, we can evaluate to what extent the in-context model is approximating Bayesian
                  inference. By applying Monte Carlo techniques to the approximated in-context prior, we can sample a
                  posterior distribution that should match the one we approximate using MLE sampling of the in-context
                  predictions.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>



      <section class="section hero ">
        <div class="container is-max-desktop">
          <div><img class="figure"
              src="./llm-elicited-priors/static/images/mc_on_prior_vs_posterior_split_1_grid_low_posterior_error.png" />
            <h2 class="figure-caption has-text-centered">
              Histograms of the posterior parameter samples approximated through MLE sampling of
              in-context predictions compared to those calculated through Monte Carlo sampling of the in-context prior
              parameter samples.
            </h2>
          </div>
        </div>
      </section>


      <!-- Does in-context learning approximate bayesian inference? -->
      <section class="section hero">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="content section-text section-box">
                <p>
                  The above figure shows these two distributions, that should match if our approximations are good and
                  if the LLM is performing Bayesian inference in-context.
                </p>
                <p>
                  Since we make an in-accurate approximation of the posterior distribution for the Breast Cancer and
                  Hypothyroid prediction tasks, we will ignore it.
                  However, for the other tasks our approximations for the prior and posterior
                  in-context distributions have low error.
                </p>
                <p>
                  In the case of Heart Disease prediction, the difference in the posterior distributions estimated
                  through
                  MLE sampling and using Monte Carlo methods differ significantly suggesting that the LLM is not
                  approximating Bayesian inference for this task. On the other hand, for the Diabetes predictive task,
                  both distributions are more similar, signifying that in this case the
                  language model is performing Bayesian inference in-context.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>



      <!-- Model selection -->
      <section class="section hero">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="section-title">The Bayes factor for model selection</h2>
              <div class="content section-text section-box">
                <p>
                  We can also calculate the Bayes factor between the prior elicitation predictions and those made using
                  in-context learning. The figures show the prior accuracy and MSE as well as the prior likelihood on 25
                  data points from each task.
                  Whether prior elicitation or in-context learning provides greater likelihoods depends on the task,
                  with both methods being the better choice over a non-informative prior for all cases tested.
                  When factoring in the methods' abilities to estimate Bayesian inference and the cost of producing
                  predictions however, prior elicitation is likely the better option for the cases tested.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>




      <section class="section hero ">
        <div class="container is-max-desktop">
          <div><img class="figure" src="./llm-elicited-priors/static/images/bayes_factor_grid_ll.png" />
            <h2 class="figure-caption has-text-centered">
              The prior marginal likelihood of in-context learning and prior elicitation
              predictions. The Bayes factor is also reported, where possible. This was calculated over 10 samples of 25
              data
              points.
            </h2>
          </div>
        </div>
      </section>




      <!-- Model selection -->
      <section class="section hero">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="section-title">The impact</h2>
              <div class="content section-text section-box">
                <p>
                  Performing prior elicitation using language models proves to be an effective technique to improve
                  probabilistic model performance in the low data regime.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>



      <section class="section hero ">
        <div class="container is-max-desktop">
          <div><img class="figure" style="width: 75%;"
              src="./llm-elicited-priors/static/images/elicitation_results_lineplot_uti_with_dates.png" />
            <h2 class="figure-caption has-text-centered">
              Line plot of the accuracy of the posterior predictive distribution on a test set for the UTI task, using
              the
              LLM-elicited priors and the uninformative prior. The \( x \) axis refers to the number of days since the
              first
              label was collected in our study.
            </h2>
          </div>
        </div>
      </section>



      <!-- Model selection -->
      <section class="section hero">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="content section-text section-box">
                <p>
                  In the figure above we plot the length of time it took to collect a given number of labels against the
                  accuracy of a model using an uninformative prior and one elicited from a language model.
                  This result illustrates the usefulness of prior elicitation, since we can achieve comparable (and
                  ultimately better) accuracy with less data points, and therefore less data collection time.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- Image carousel -->
      <!-- <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="llm-elicited-priors/static/images/carousel1.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              First image description.
            </h2>
          </div>
          <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="llm-elicited-priors/static/images/carousel2.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Second image description.
            </h2>
          </div>
          <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="llm-elicited-priors/static/images/carousel3.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Third image description.
            </h2>
          </div>
          <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="llm-elicited-priors/static/images/carousel4.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Fourth image description.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section> -->
      <!-- End image carousel -->




      <!-- Youtube video -->
      <!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">

            <div class="publication-video"> -->
      <!-- Youtube embed code here -->
      <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section> -->
      <!-- End youtube video -->


      <!-- Video carousel -->
      <!-- <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Another Carousel</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
      <!-- Your video file here -->
      <!-- <source src="llm-elicited-priors/static/videos/carousel1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
      <!-- Your video file here -->
      <!-- <source src="llm-elicited-priors/static/videos/carousel2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video3">
            <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
      <!-- Your video file here -->
      <!-- <source src="llm-elicited-priors/static/videos/carousel3.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->
      <!-- End video carousel -->






      <!-- Paper poster -->
      <!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>

        <iframe src="llm-elicited-priors/static/pdfs/sample.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section> -->
      <!--End paper poster -->



      <!--BibTex citation -->
      <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="section-title">BibTeX</h2>
          <pre><code>@article{capstick2024autoelicit,
  title={AutoElicit: AutoElicit: Using Large Language Models for Expert Prior Elicitation in Predictive Modelling},
  author={Capstick, Alexander and Krishnan, Rahul G and Barnaghi, Payam},
  journal={arXiv preprint arXiv:2411.17284},
  year={2024}
}</code></pre>
        </div>
      </section>
      <!--End BibTex citation -->


      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This page was adapted from the <a
                    href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                    Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"
                    target="_blank">Nerfies</a> project page.
                  <br> This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>

              </div>
            </div>
          </div>
        </div>
      </footer>

      <!-- Statcounter tracking code -->

      <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

      <!-- End of Statcounter Code -->

</body>

</html>